{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport sys\nfrom glob import glob\nimport yaml\nimport scipy.io\nimport pandas as pd\nfrom numpy import rollaxis, swapaxes\nimport os\nimport cv2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-01T11:02:07.53678Z","iopub.execute_input":"2021-08-01T11:02:07.537717Z","iopub.status.idle":"2021-08-01T11:02:07.953656Z","shell.execute_reply.started":"2021-08-01T11:02:07.537588Z","shell.execute_reply":"2021-08-01T11:02:07.952585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input,Lambda,Dense\nfrom keras.layers import Conv2D,Dropout,Flatten\nfrom keras.layers import MaxPooling2D\nfrom keras.models import model_from_yaml\nfrom keras import Sequential\nfrom tensorflow.keras.optimizers import SGD,RMSprop,Adam\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import load_img,img_to_array\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint,CSVLogger\nfrom keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:02:07.955717Z","iopub.execute_input":"2021-08-01T11:02:07.956207Z","iopub.status.idle":"2021-08-01T11:02:13.641929Z","shell.execute_reply.started":"2021-08-01T11:02:07.956161Z","shell.execute_reply":"2021-08-01T11:02:13.640844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"melanoma_dir=\"../input/melanoma/datasets/datasets/edra_cropped/ready\"\nretina_dir=\"../input/melanoma/datasets/datasets/retina\"\ngit_repo_path=\"../input/melanoma/melanoma-transfer/melanoma-transfer\"\n","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:02:13.64414Z","iopub.execute_input":"2021-08-01T11:02:13.644522Z","iopub.status.idle":"2021-08-01T11:02:13.65304Z","shell.execute_reply.started":"2021-08-01T11:02:13.644489Z","shell.execute_reply":"2021-08-01T11:02:13.652032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_files(datadir, listImages=[], left_only=False):\n    fs = glob('{}/*'.format(datadir))\n    #print(\"Total images:\",len(fs),len(glob(datadir+\"/*\")))\n    if left_only:\n        fs = [f for f in fs if 'left' in f]\n    if listImages != []:                                                        # <-- Adapted to return images from the list\n        image_name = [img.split(\".\")[0] for img in listImages]           #listImages contains .tiff and datadir contains .jpg, so extracting image name\n        fs = [f for f in fs if f.split(\"/\")[-1].split(\".\")[0] in image_name]                  # Useful for running with 5x2-fold cross-validation\n        print(\"images listed:\",len(listImages),\" images loaded:\",len(fs))\n    return np.array(sorted(fs))\n\ndef get_labels(names, labels=None, label_file=None,\n               per_patient=False):\n    if labels is None:\n        labels = pd.read_csv(label_file,\n                             index_col=0).loc[names].values.flatten()\n    if per_patient:\n        left = np.array(['left' in n for n in names])\n        return np.vstack([labels[left], labels[~left]]).T\n    else:\n        return labels","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:02:13.657455Z","iopub.execute_input":"2021-08-01T11:02:13.657744Z","iopub.status.idle":"2021-08-01T11:02:13.673604Z","shell.execute_reply.started":"2021-08-01T11:02:13.657702Z","shell.execute_reply":"2021-08-01T11:02:13.67244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(protocol,fold,train_dir,train_retina):\n    \n    if train_retina:\n        files = get_image_files(train_dir)\n    else:\n        folds = yaml.full_load(open(git_repo_path+'/folds/'+protocol+'.yml'))\n        print(\"The images are loaded from:\",git_repo_path+'/folds/'+protocol+'.yml')\n        f0, f1 = fold.split('x')\n        train_list = folds['Fold_' + f0][int(f1)-1]\n        files = get_image_files(train_dir, train_list)\n        names = [os.path.basename(x).split('.')[0] for x in files]\n        labels = get_labels(names, label_file=git_repo_path+'/folds/'+protocol+'.csv').astype(np.int32)\n        if protocol!=\"protocol3\":\n            labels=to_categorical(labels,2)\n        else:\n            labels=to_categorical(labels,3)\n        images=[]\n        for file in files:\n            img=load_img(file,target_size=(224,224))\n            images.append(img_to_array(img))\n        images=np.array(images)\n        print(\"Input shape:   Images:\",images.shape,\" labels:\",labels.shape)\n            \n        return images,labels","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:02:13.675167Z","iopub.execute_input":"2021-08-01T11:02:13.675734Z","iopub.status.idle":"2021-08-01T11:02:13.690637Z","shell.execute_reply.started":"2021-08-01T11:02:13.675691Z","shell.execute_reply":"2021-08-01T11:02:13.689464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def checkpoints(directory_path):\n    #Stores the best model depending on loss after every epoch\n    checkpoint_path = directory_path\n    filepath=\"weights-epoch-{epoch:02d}-loss-{loss:.2f}.hdf5\"\n    checkpoint = ModelCheckpoint(filepath=checkpoint_path+\"/\"+filepath,monitor=\"loss\",mode=\"min\",save_best_only=True, save_weights_only=True, verbose=1)\n\n\n\n    #Stops the training if the val_loss doesn't minimize for 20 consecutive epochs\n    earlystop = EarlyStopping(monitor=\"loss\",patience = 20,mode=\"min\") \n\n\n    #Reduce the learning rate by 0.5 if the val_loss doesn't decrease with 2 consecutive epochs\n    learning_rate_reduction = ReduceLROnPlateau(monitor=\"loss\",patience = 2,factor = 0.05,mode=\"min\",min_lr = 0.00001)\n\n    return [checkpoint,earlystop,learning_rate_reduction]","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:02:13.6924Z","iopub.execute_input":"2021-08-01T11:02:13.692854Z","iopub.status.idle":"2021-08-01T11:02:13.704548Z","shell.execute_reply.started":"2021-08-01T11:02:13.692812Z","shell.execute_reply":"2021-08-01T11:02:13.703539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vgg_m(classes):\n    model = Sequential()\n    model.add(Conv2D(filters=96,kernel_size=(7,7),strides=(2,2), padding='valid', activation='relu',input_shape=(224,224,3)))\n    model.add(Lambda(tf.nn.local_response_normalization))\n    model.add(MaxPooling2D((3,3), strides=(2,2)))\n    model.add(Conv2D(filters=256,kernel_size=(5,5),strides=(2,2), padding='same', activation='relu'))\n    model.add(Lambda(tf.nn.local_response_normalization))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1), padding='same', activation='relu'))\n    model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1), padding='same', activation='relu'))\n    model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1), padding='same', activation='relu'))\n    model.add(MaxPooling2D((3,3), strides=(2,2)))\n    model.add(Flatten())\n    model.add(Dense(4096, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(4096, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(classes, activation=\"softmax\"))\n\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:02:13.705947Z","iopub.execute_input":"2021-08-01T11:02:13.706252Z","iopub.status.idle":"2021-08-01T11:02:13.722552Z","shell.execute_reply.started":"2021-08-01T11:02:13.706222Z","shell.execute_reply":"2021-08-01T11:02:13.721271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rolling(roll_me): #input- (7,7,3,96) output-(96,3,7,7)\n    a = swapaxes(roll_me, 3, 0)\n    a = swapaxes(a, 1, 2)\n    a = swapaxes(a, 2, 3)\n    return a","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:02:13.726037Z","iopub.execute_input":"2021-08-01T11:02:13.726854Z","iopub.status.idle":"2021-08-01T11:02:13.74067Z","shell.execute_reply.started":"2021-08-01T11:02:13.72681Z","shell.execute_reply":"2021-08-01T11:02:13.739322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_load_weight(model):\n    #vggm\n    mat = scipy.io.loadmat('../input/melanoma/datasets/datasets/imagenet/imagenet-vgg-m.mat')\n    #vggm\n    conv2d_58 = [np.array(rolling(mat['layers'][0][0][0][0][2][0][0]),dtype='float32').transpose(), np.array(np.squeeze(mat['layers'][0][0][0][0][2][0][1]),dtype='float32')]\n    conv2d_59 = [np.array(rolling(mat['layers'][0][4][0][0][2][0][0]),dtype='float32').transpose(), np.array(np.squeeze(mat['layers'][0][4][0][0][2][0][1]),dtype='float32')]\n    conv2d_60 = [np.array(rolling(mat['layers'][0][8][0][0][2][0][0]),dtype='float32').transpose(), np.array(np.squeeze(mat['layers'][0][8][0][0][2][0][1]),dtype='float32')]\n    conv2d_61 = [np.array(rolling(mat['layers'][0][10][0][0][2][0][0]),dtype='float32').transpose(), np.array(np.squeeze(mat['layers'][0][10][0][0][2][0][1]),dtype='float32')]\n    conv2d_62 = [np.array(rolling(mat['layers'][0][12][0][0][2][0][0]),dtype='float32').transpose(), np.array(np.squeeze(mat['layers'][0][12][0][0][2][0][1]),dtype='float32')]\n    dense_28 = [np.array(np.reshape(rollaxis(mat['layers'][0][15][0][0][2][0][0], 2),(18432,4096)),dtype='float32'), np.array(np.squeeze(mat['layers'][0][15][0][0][2][0][1]),dtype='float32')]\n    dense_29 = [np.array(np.squeeze(mat['layers'][0][17][0][0][2][0][0]),dtype='float32'), np.array(np.squeeze(mat['layers'][0][17][0][0][2][0][1]),dtype='float32')]\n    dense_30 = [np.array(np.squeeze(mat['layers'][0][19][0][0][2][0][0]),dtype='float32'), np.array(np.squeeze(mat['layers'][0][19][0][0][2][0][1]),dtype='float32')]\n    weights= [conv2d_58,[],[],conv2d_59,[],[],conv2d_60,conv2d_61,conv2d_62,[],[],dense_28,[],dense_29,[],[]] #last layer shape in pre-trained model is (4096,1000), needed (4096,2)\n    i=0\n    for layer in model.layers:\n        if(i == len(weights)-1):\n            break       #not loading the weight of the last layer\n        layer.set_weights(weights[i])\n        i=i+1\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:02:13.745079Z","iopub.execute_input":"2021-08-01T11:02:13.745409Z","iopub.status.idle":"2021-08-01T11:02:13.769627Z","shell.execute_reply.started":"2021-08-01T11:02:13.74538Z","shell.execute_reply":"2021-08-01T11:02:13.768354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main(train_dir,model_name,protocol,train_retina=False):\n    #protocol1,protocol2,protocol3\n    num_output=2\n    if protocol == \"protocol3\":\n        num_output=3\n    model_save_path=\"./\"+model_name+\"_\"+protocol+\"_scratch_weights\"\n    os.mkdir(model_save_path)\n    for i in range(1,6):\n        for j in range(1,3):\n            fold=str(i)+\"x\"+str(j)\n            dest_path=model_save_path+\"/\"+fold\n            os.mkdir(dest_path)\n            print(\"-------------------training:\",fold,\"--------------------------------\")\n            \n            #Load the data\n            print(\"Loading Data\")\n            images,label=load_data(protocol,fold,train_dir,train_retina)\n            datagen = ImageDataGenerator(rotation_range=20,width_shift_range=0.2,height_shift_range=0.2,horizontal_flip=True,validation_split=0.2)\n\n            \n            print(\"VGGM model\")\n            vggm=vgg_m(num_output)\n            #print(vggm.summary())\n            my_callbacks = checkpoints(dest_path)\n            \n            vggm.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0005), metrics=['accuracy',tf.keras.metrics.AUC()])\n            \n            vggm.fit(datagen.flow(images, label, batch_size=12,subset='training'),\n                     validation_data=datagen.flow(images,label, batch_size=8, subset='validation'),\n                     epochs=150,\n                     verbose=1,\n                     callbacks=my_callbacks,)\n            \n            files= sorted(glob(dest_path+\"/*\"))\n            file_name=files[-1]\n            for file in files:\n                if file != file_name:\n                    os.remove(file)\n            ","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:02:13.771552Z","iopub.execute_input":"2021-08-01T11:02:13.772425Z","iopub.status.idle":"2021-08-01T11:02:13.788387Z","shell.execute_reply.started":"2021-08-01T11:02:13.772376Z","shell.execute_reply":"2021-08-01T11:02:13.787227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main(melanoma_dir,\"E\",\"protocol3\")","metadata":{"execution":{"iopub.status.busy":"2021-08-01T11:02:13.790208Z","iopub.execute_input":"2021-08-01T11:02:13.79077Z","iopub.status.idle":"2021-08-01T11:02:38.84343Z","shell.execute_reply.started":"2021-08-01T11:02:13.790724Z","shell.execute_reply":"2021-08-01T11:02:38.840136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}