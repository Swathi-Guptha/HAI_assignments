{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport sys\nfrom glob import glob\nimport yaml\nimport scipy.io\nimport pandas as pd\nfrom numpy import rollaxis, swapaxes\nimport os\nimport cv2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-01T16:33:00.295085Z","iopub.execute_input":"2021-08-01T16:33:00.295549Z","iopub.status.idle":"2021-08-01T16:33:00.630604Z","shell.execute_reply.started":"2021-08-01T16:33:00.295406Z","shell.execute_reply":"2021-08-01T16:33:00.629774Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input,Lambda,Dense\nfrom keras.layers import Conv2D,Dropout,Flatten\nfrom keras.layers import MaxPooling2D\nfrom keras.models import model_from_yaml\nfrom keras import Sequential\nfrom tensorflow.keras.optimizers import SGD,RMSprop,Adam\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import load_img,img_to_array\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint,CSVLogger\nfrom keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2021-08-01T16:33:00.632212Z","iopub.execute_input":"2021-08-01T16:33:00.632649Z","iopub.status.idle":"2021-08-01T16:33:04.696623Z","shell.execute_reply.started":"2021-08-01T16:33:00.632610Z","shell.execute_reply":"2021-08-01T16:33:04.695593Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"melanoma_dir=\"../input/melanoma/datasets/datasets/edra_cropped/ready\"\nretina_dir=\"../input/melanoma/datasets/datasets/retina\"\ngit_repo_path=\"../input/melanoma/melanoma-transfer/melanoma-transfer\"","metadata":{"execution":{"iopub.status.busy":"2021-08-01T16:33:04.698538Z","iopub.execute_input":"2021-08-01T16:33:04.698882Z","iopub.status.idle":"2021-08-01T16:33:04.704801Z","shell.execute_reply.started":"2021-08-01T16:33:04.698852Z","shell.execute_reply":"2021-08-01T16:33:04.702120Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def get_image_files(datadir, listImages=[], left_only=False):\n    fs = glob('{}/*'.format(datadir))\n    #print(\"Total images:\",len(fs),len(glob(datadir+\"/*\")))\n    if left_only:\n        fs = [f for f in fs if 'left' in f]\n    if listImages != []:                                                        # <-- Adapted to return images from the list\n        image_name = [img.split(\".\")[0] for img in listImages]           #listImages contains .tiff and datadir contains .jpg, so extracting image name\n        fs = [f for f in fs if f.split(\"/\")[-1].split(\".\")[0] in image_name]                  # Useful for running with 5x2-fold cross-validation\n        print(\"images listed:\",len(listImages),\" images loaded:\",len(fs))\n    return np.array(sorted(fs))\n\ndef get_labels(names, labels=None, label_file=None,\n               per_patient=False):\n    if labels is None:\n        labels = pd.read_csv(label_file,\n                             index_col=0).loc[names].values.flatten()\n    if per_patient:\n        left = np.array(['left' in n for n in names])\n        return np.vstack([labels[left], labels[~left]]).T\n    else:\n        return labels","metadata":{"execution":{"iopub.status.busy":"2021-08-01T16:33:04.708833Z","iopub.execute_input":"2021-08-01T16:33:04.709166Z","iopub.status.idle":"2021-08-01T16:33:04.721769Z","shell.execute_reply.started":"2021-08-01T16:33:04.709137Z","shell.execute_reply":"2021-08-01T16:33:04.720841Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def load_data(protocol,fold,directory,train_retina):\n    \n    if train_retina:\n        files = get_image_files(directory)\n    else:\n        folds = yaml.full_load(open(git_repo_path+'/folds/'+protocol+'.yml'))\n        f0, f1 = fold.split('x')\n        train_list = folds['Fold_' + f0][int(f1)-1]\n        test_list  = folds['Fold_' + f0][0 if f1=='2' else 1]\n        \n        train_files = get_image_files(directory, train_list)\n        train_names = [os.path.basename(x).split('.')[0] for x in train_files]\n        train_labels = get_labels(train_names, label_file=git_repo_path+'/folds/'+protocol+'.csv').astype(np.int32)\n        \n        test_files = get_image_files(directory, test_list)\n        test_names = [os.path.basename(x).split('.')[0] for x in test_files]\n        test_labels = get_labels(test_names, label_file=git_repo_path+'/folds/'+protocol+'.csv').astype(np.int32)\n        \n        if protocol!=\"protocol3\":\n            train_labels=to_categorical(train_labels,2)\n            test_labels=to_categorical(test_labels,2)\n        else:\n            train_labels=to_categorical(train_labels,3)\n            test_labels=to_categorical(test_labels,3)\n        \n        train_images=[]\n        for file in train_files:\n            img=load_img(file,target_size=(224,224))\n            train_images.append(img_to_array(img))\n        train_images=np.array(train_images)\n        \n        test_images=[]\n        for file in test_files:\n            img=load_img(file,target_size=(224,224))\n            test_images.append(img_to_array(img))\n        test_images=np.array(test_images)\n        print(\"Train images:   Images:\",train_images.shape,\" labels:\",train_labels.shape)\n        print(\"Test images:   Images:\",test_images.shape,\" labels:\",test_labels.shape)\n            \n        return train_images,train_labels,test_images,test_labels\n","metadata":{"execution":{"iopub.status.busy":"2021-08-01T16:33:04.723044Z","iopub.execute_input":"2021-08-01T16:33:04.726877Z","iopub.status.idle":"2021-08-01T16:33:04.740129Z","shell.execute_reply.started":"2021-08-01T16:33:04.726845Z","shell.execute_reply":"2021-08-01T16:33:04.739146Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def vgg_m(classes):\n    model = Sequential()\n    model.add(Conv2D(filters=96,kernel_size=(7,7),strides=(2,2), padding='valid', activation='relu',input_shape=(224,224,3)))\n    model.add(Lambda(tf.nn.local_response_normalization))\n    model.add(MaxPooling2D((3,3), strides=(2,2)))\n    model.add(Conv2D(filters=256,kernel_size=(5,5),strides=(2,2), padding='same', activation='relu'))\n    model.add(Lambda(tf.nn.local_response_normalization))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1), padding='same', activation='relu'))\n    model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1), padding='same', activation='relu'))\n    model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1), padding='same', activation='relu'))\n    model.add(MaxPooling2D((3,3), strides=(2,2)))\n    model.add(Flatten())\n    model.add(Dense(4096, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(4096, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(classes, activation=\"softmax\"))\n\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-01T16:33:04.741167Z","iopub.execute_input":"2021-08-01T16:33:04.741414Z","iopub.status.idle":"2021-08-01T16:33:04.755852Z","shell.execute_reply.started":"2021-08-01T16:33:04.741391Z","shell.execute_reply":"2021-08-01T16:33:04.754813Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def main(train_dir,protocol,model_name,weight_dir,train_retina=False):\n    num_output=2\n    if protocol == \"protocol3\":\n        num_output=3\n    features_save_path=\"./\"+model_name+\"_\"+protocol+\"_features\"\n    os.mkdir(features_save_path)\n    for i in range(1,6):\n        for j in range(1,3):\n            fold=str(i)+\"x\"+str(j)\n            dest_path=features_save_path+\"/\"+fold\n            os.mkdir(dest_path)\n            print(weight_dir+\"/\"+fold,\" \",glob(weight_dir+\"/\"+fold+\"/*.hdf5\"))\n            weight_path=glob(weight_dir+\"/\"+fold+\"/*.hdf5\")[0]\n            \n            #Load the data\n            train_images,train_labels,test_images,test_labels=load_data(protocol,fold,train_dir,train_retina)\n            \n            print(\"VGGM model\")\n            vggm=vgg_m(num_output)\n            \n                    \n            print(\"Loading pre-trained weights\")\n            vggm.load_weights(weight_path)\n            vggm.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.005), metrics=['accuracy',tf.keras.metrics.AUC()])\n\n            \n            print(\"-------------------extracting features for fold:\",fold,\"--------------------------------\")\n            \n            extractor = Model(inputs=vggm.inputs,outputs=[layer.output for layer in vggm.layers])\n            \n            train_features=[]\n            train_feature_labels=[]\n            for img,label in zip(train_images,train_labels):\n                arr4d = np.expand_dims(img, 0)\n                extracted_features=extractor(arr4d)\n                train_features.append(extracted_features[-2]) #Saving 4096 feature from last Dense layer\n                train_feature_labels.append(label)\n            np.save(os.path.join(dest_path,\"train_features.npy\"),train_features)\n            np.save(os.path.join(dest_path,\"train_featureLabels.npy\"),train_feature_labels)\n            \n            test_features=[]\n            test_feature_labels=[]\n            for img,label in zip(test_images,test_labels):\n                arr4d = np.expand_dims(img, 0)\n                extracted_features=extractor(arr4d)\n                test_features.append(extracted_features[-2]) #Saving 4096 feature from last Dense layer\n                test_feature_labels.append(label)\n            np.save(os.path.join(dest_path,\"test_features.npy\"),test_features)\n            np.save(os.path.join(dest_path,\"test_featureLabels.npy\"),test_feature_labels)\n\n            ","metadata":{"execution":{"iopub.status.busy":"2021-08-01T16:33:04.758458Z","iopub.execute_input":"2021-08-01T16:33:04.758864Z","iopub.status.idle":"2021-08-01T16:33:04.774721Z","shell.execute_reply.started":"2021-08-01T16:33:04.758757Z","shell.execute_reply":"2021-08-01T16:33:04.773938Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#change the model_name to create the folder depending on the model\n#Also change the path to model weight\n#To get weights of different protocol go to melanoma_skin_cancer version 6,7,8 ouputs and load in E_protocol1_weights dataset\nmain(melanoma_dir,\"protocol1\",\"A\",\"../input/model-a-weights/E_protocol1_scratch_weights\")\n","metadata":{"execution":{"iopub.status.busy":"2021-08-01T16:33:04.775863Z","iopub.execute_input":"2021-08-01T16:33:04.777125Z","iopub.status.idle":"2021-08-01T16:36:03.606470Z","shell.execute_reply.started":"2021-08-01T16:33:04.777091Z","shell.execute_reply":"2021-08-01T16:36:03.605587Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"../input/model-a-weights/E_protocol1_scratch_weights/1x1   ['../input/model-a-weights/E_protocol1_scratch_weights/1x1/weights-epoch-30-loss-0.65.hdf5']\nimages listed: 487  images loaded: 475\nimages listed: 487  images loaded: 473\nTrain images:   Images: (475, 224, 224, 3)  labels: (475, 2)\nTest images:   Images: (473, 224, 224, 3)  labels: (473, 2)\nVGGM model\nLoading pre-trained weights\n-------------------extracting features for fold: 1x1 --------------------------------\n../input/model-a-weights/E_protocol1_scratch_weights/1x2   ['../input/model-a-weights/E_protocol1_scratch_weights/1x2/weights-epoch-18-loss-0.64.hdf5']\nimages listed: 487  images loaded: 473\nimages listed: 487  images loaded: 475\nTrain images:   Images: (473, 224, 224, 3)  labels: (473, 2)\nTest images:   Images: (475, 224, 224, 3)  labels: (475, 2)\nVGGM model\nLoading pre-trained weights\n-------------------extracting features for fold: 1x2 --------------------------------\n../input/model-a-weights/E_protocol1_scratch_weights/2x1   ['../input/model-a-weights/E_protocol1_scratch_weights/2x1/weights-epoch-21-loss-0.64.hdf5']\nimages listed: 487  images loaded: 473\nimages listed: 487  images loaded: 475\nTrain images:   Images: (473, 224, 224, 3)  labels: (473, 2)\nTest images:   Images: (475, 224, 224, 3)  labels: (475, 2)\nVGGM model\nLoading pre-trained weights\n-------------------extracting features for fold: 2x1 --------------------------------\n../input/model-a-weights/E_protocol1_scratch_weights/2x2   ['../input/model-a-weights/E_protocol1_scratch_weights/2x2/weights-epoch-18-loss-0.65.hdf5']\nimages listed: 487  images loaded: 475\nimages listed: 487  images loaded: 473\nTrain images:   Images: (475, 224, 224, 3)  labels: (475, 2)\nTest images:   Images: (473, 224, 224, 3)  labels: (473, 2)\nVGGM model\nLoading pre-trained weights\n-------------------extracting features for fold: 2x2 --------------------------------\n../input/model-a-weights/E_protocol1_scratch_weights/3x1   ['../input/model-a-weights/E_protocol1_scratch_weights/3x1/weights-epoch-98-loss-0.56.hdf5']\nimages listed: 486  images loaded: 474\nimages listed: 488  images loaded: 474\nTrain images:   Images: (474, 224, 224, 3)  labels: (474, 2)\nTest images:   Images: (474, 224, 224, 3)  labels: (474, 2)\nVGGM model\nLoading pre-trained weights\n-------------------extracting features for fold: 3x1 --------------------------------\n../input/model-a-weights/E_protocol1_scratch_weights/3x2   ['../input/model-a-weights/E_protocol1_scratch_weights/3x2/weights-epoch-21-loss-0.65.hdf5']\nimages listed: 488  images loaded: 474\nimages listed: 486  images loaded: 474\nTrain images:   Images: (474, 224, 224, 3)  labels: (474, 2)\nTest images:   Images: (474, 224, 224, 3)  labels: (474, 2)\nVGGM model\nLoading pre-trained weights\n-------------------extracting features for fold: 3x2 --------------------------------\n../input/model-a-weights/E_protocol1_scratch_weights/4x1   ['../input/model-a-weights/E_protocol1_scratch_weights/4x1/weights-epoch-32-loss-0.65.hdf5']\nimages listed: 488  images loaded: 474\nimages listed: 486  images loaded: 474\nTrain images:   Images: (474, 224, 224, 3)  labels: (474, 2)\nTest images:   Images: (474, 224, 224, 3)  labels: (474, 2)\nVGGM model\nLoading pre-trained weights\n-------------------extracting features for fold: 4x1 --------------------------------\n../input/model-a-weights/E_protocol1_scratch_weights/4x2   ['../input/model-a-weights/E_protocol1_scratch_weights/4x2/weights-epoch-19-loss-0.64.hdf5']\nimages listed: 486  images loaded: 474\nimages listed: 488  images loaded: 474\nTrain images:   Images: (474, 224, 224, 3)  labels: (474, 2)\nTest images:   Images: (474, 224, 224, 3)  labels: (474, 2)\nVGGM model\nLoading pre-trained weights\n-------------------extracting features for fold: 4x2 --------------------------------\n../input/model-a-weights/E_protocol1_scratch_weights/5x1   ['../input/model-a-weights/E_protocol1_scratch_weights/5x1/weights-epoch-91-loss-0.54.hdf5']\nimages listed: 488  images loaded: 473\nimages listed: 486  images loaded: 475\nTrain images:   Images: (473, 224, 224, 3)  labels: (473, 2)\nTest images:   Images: (475, 224, 224, 3)  labels: (475, 2)\nVGGM model\nLoading pre-trained weights\n-------------------extracting features for fold: 5x1 --------------------------------\n../input/model-a-weights/E_protocol1_scratch_weights/5x2   ['../input/model-a-weights/E_protocol1_scratch_weights/5x2/weights-epoch-21-loss-0.65.hdf5']\nimages listed: 486  images loaded: 475\nimages listed: 488  images loaded: 473\nTrain images:   Images: (475, 224, 224, 3)  labels: (475, 2)\nTest images:   Images: (473, 224, 224, 3)  labels: (473, 2)\nVGGM model\nLoading pre-trained weights\n-------------------extracting features for fold: 5x2 --------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('sequence', 'zip', './A_protocol1_features')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T16:36:38.782346Z","iopub.execute_input":"2021-08-01T16:36:38.782715Z","iopub.status.idle":"2021-08-01T16:36:43.978651Z","shell.execute_reply.started":"2021-08-01T16:36:38.782681Z","shell.execute_reply":"2021-08-01T16:36:43.977815Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/sequence.zip'"},"metadata":{}}]},{"cell_type":"code","source":"import os\nos.chdir('./E_protocol2_features')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T08:39:57.415345Z","iopub.execute_input":"2021-08-01T08:39:57.416385Z","iopub.status.idle":"2021-08-01T08:39:57.421133Z","shell.execute_reply.started":"2021-08-01T08:39:57.416313Z","shell.execute_reply":"2021-08-01T08:39:57.419647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('sequence.zip')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T08:09:03.528283Z","iopub.execute_input":"2021-08-01T08:09:03.528643Z","iopub.status.idle":"2021-08-01T08:09:03.534186Z","shell.execute_reply.started":"2021-08-01T08:09:03.528613Z","shell.execute_reply":"2021-08-01T08:09:03.53346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}