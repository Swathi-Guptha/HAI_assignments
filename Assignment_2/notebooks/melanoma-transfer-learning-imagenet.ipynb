{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nmelanoma_balance_weights = np.array([1.4595, 3.1758]) # set of resampling weights that yields balanced classes\nisic_balance_weights = np.array([1.2405, 5.1572])\nmelanoma_prot3_balance_weights = np.array([23.2142, 3.6792, 1.4595])\nmelanoma_std = np.array([ 49.33694864,  56.56751696,  59.42470697], dtype=np.float32) # channel standard deviations\nmelanoma_mean = np.array([ 198.19906616, 170.38525391, 155.49664307], dtype=np.float32) # channel means\nmelanoma_U = np.array([[-0.51556925,  0.77283555,  0.35053246],\n \t\t\t\t [-0.60600832, -0.04596143, -0.78214996],\n \t\t\t\t [-0.60304644, -0.6169369,   0.49839384]] ,dtype=np.float32)\nmelanoma_EV = np.array([ 102.92342015, 25.71846177, 11.24928707], dtype=np.float32)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-30T14:40:38.865015Z","iopub.execute_input":"2021-07-30T14:40:38.865386Z","iopub.status.idle":"2021-07-30T14:40:38.880168Z","shell.execute_reply.started":"2021-07-30T14:40:38.865297Z","shell.execute_reply":"2021-07-30T14:40:38.87915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport sys\nfrom glob import glob\nimport yaml\nimport scipy.io\nimport pandas as pd\nfrom numpy import rollaxis, swapaxes\nimport os\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2021-07-31T08:47:25.442629Z","iopub.execute_input":"2021-07-31T08:47:25.443083Z","iopub.status.idle":"2021-07-31T08:47:25.837844Z","shell.execute_reply.started":"2021-07-31T08:47:25.442981Z","shell.execute_reply":"2021-07-31T08:47:25.836638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input,Lambda,Dense\nfrom keras.layers import Conv2D,Dropout,Flatten\nfrom keras.layers import MaxPooling2D\nfrom keras.models import model_from_yaml\nfrom keras import Sequential\nfrom tensorflow.keras.optimizers import SGD,RMSprop,Adam\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import load_img,img_to_array\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint,CSVLogger\nfrom keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2021-07-31T08:47:26.465247Z","iopub.execute_input":"2021-07-31T08:47:26.465627Z","iopub.status.idle":"2021-07-31T08:47:32.12293Z","shell.execute_reply.started":"2021-07-31T08:47:26.465595Z","shell.execute_reply":"2021-07-31T08:47:32.121794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"melanoma_dir=\"../input/melanoma/datasets/datasets/edra_cropped/ready\"\nretina_dir=\"../input/melanoma/datasets/datasets/retina\"\ngit_repo_path=\"../input/melanoma/melanoma-transfer/melanoma-transfer\"","metadata":{"execution":{"iopub.status.busy":"2021-07-31T08:47:32.12468Z","iopub.execute_input":"2021-07-31T08:47:32.125116Z","iopub.status.idle":"2021-07-31T08:47:32.134502Z","shell.execute_reply.started":"2021-07-31T08:47:32.125071Z","shell.execute_reply":"2021-07-31T08:47:32.133322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_files(datadir, listImages=[], left_only=False):\n    fs = glob('{}/*'.format(datadir))\n    #print(\"Total images:\",len(fs),len(glob(datadir+\"/*\")))\n    if left_only:\n        fs = [f for f in fs if 'left' in f]\n    if listImages != []:                                                        # <-- Adapted to return images from the list\n        image_name = [img.split(\".\")[0] for img in listImages]           #listImages contains .tiff and datadir contains .jpg, so extracting image name\n        fs = [f for f in fs if f.split(\"/\")[-1].split(\".\")[0] in image_name]                  # Useful for running with 5x2-fold cross-validation\n        print(\"images listed:\",len(listImages),\" images loaded:\",len(fs))\n    return np.array(sorted(fs))\n\ndef get_labels(names, labels=None, label_file=None,\n               per_patient=False):\n    if labels is None:\n        labels = pd.read_csv(label_file,\n                             index_col=0).loc[names].values.flatten()\n    if per_patient:\n        left = np.array(['left' in n for n in names])\n        return np.vstack([labels[left], labels[~left]]).T\n    else:\n        return labels","metadata":{"execution":{"iopub.status.busy":"2021-07-31T08:47:32.139175Z","iopub.execute_input":"2021-07-31T08:47:32.139621Z","iopub.status.idle":"2021-07-31T08:47:32.150537Z","shell.execute_reply.started":"2021-07-31T08:47:32.139593Z","shell.execute_reply":"2021-07-31T08:47:32.148849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(protocol,fold,train_dir,train_retina):\n    \n    if train_retina:\n        files = get_image_files(train_dir)\n    else:\n        folds = yaml.full_load(open(git_repo_path+'/folds/'+protocol+'.yml'))\n        print(\"The images are loaded from:\",git_repo_path+'/folds/'+protocol+'.yml')\n        f0, f1 = fold.split('x')\n        train_list = folds['Fold_' + f0][int(f1)-1]\n        files = get_image_files(train_dir, train_list)\n        names = [os.path.basename(x).split('.')[0] for x in files]\n        labels = get_labels(names, label_file=git_repo_path+'/folds/'+protocol+'.csv').astype(np.int32)\n        if protocol!=\"protocol3\":\n            labels=to_categorical(labels,2)\n        else:\n            labels=to_categorical(labels,3)\n        images=[]\n        for file in files:\n            img=load_img(file,target_size=(224,224))\n            images.append(img_to_array(img))\n        images=np.array(images)\n        print(\"Input shape:   Images:\",images.shape,\" labels:\",labels.shape)\n            \n        return images,labels\n","metadata":{"execution":{"iopub.status.busy":"2021-07-31T08:47:32.153696Z","iopub.execute_input":"2021-07-31T08:47:32.154305Z","iopub.status.idle":"2021-07-31T08:47:32.168099Z","shell.execute_reply.started":"2021-07-31T08:47:32.154107Z","shell.execute_reply":"2021-07-31T08:47:32.166884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def checkpoints(directory_path):\n    #Stores the best model depending on loss after every epoch\n    checkpoint_path = directory_path\n    filepath=\"weights-epoch-{epoch:02d}-loss-{loss:.2f}.hdf5\"\n    checkpoint = ModelCheckpoint(filepath=checkpoint_path+\"/\"+filepath,monitor=\"loss\",mode=\"min\",save_best_only=True, save_weights_only=True, verbose=1)\n\n\n\n    #Stops the training if the val_loss doesn't minimize for 20 consecutive epochs\n    earlystop = EarlyStopping(monitor=\"loss\",patience = 20,mode=\"min\") \n\n\n    #Reduce the learning rate by 0.5 if the val_loss doesn't decrease with 2 consecutive epochs\n    learning_rate_reduction = ReduceLROnPlateau(monitor=\"loss\",patience = 2,factor = 0.5,mode=\"min\",min_lr = 0.00001)\n\n    return [checkpoint,earlystop,learning_rate_reduction]\n","metadata":{"execution":{"iopub.status.busy":"2021-07-31T08:47:32.169763Z","iopub.execute_input":"2021-07-31T08:47:32.170501Z","iopub.status.idle":"2021-07-31T08:47:32.186705Z","shell.execute_reply.started":"2021-07-31T08:47:32.170441Z","shell.execute_reply":"2021-07-31T08:47:32.185519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vgg_m(classes):\n    model = Sequential()\n    model.add(Conv2D(filters=96,kernel_size=(7,7),strides=(2,2), padding='valid', activation='relu',input_shape=(224,224,3)))\n    model.add(Lambda(tf.nn.local_response_normalization))\n    model.add(MaxPooling2D((3,3), strides=(2,2)))\n    model.add(Conv2D(filters=256,kernel_size=(5,5),strides=(2,2), padding='same', activation='relu'))\n    model.add(Lambda(tf.nn.local_response_normalization))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1), padding='same', activation='relu'))\n    model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1), padding='same', activation='relu'))\n    model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1), padding='same', activation='relu'))\n    model.add(MaxPooling2D((3,3), strides=(2,2)))\n    model.add(Flatten())\n    model.add(Dense(4096, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(4096, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(classes, activation=\"softmax\"))\n\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-31T08:47:32.188612Z","iopub.execute_input":"2021-07-31T08:47:32.18916Z","iopub.status.idle":"2021-07-31T08:47:32.204072Z","shell.execute_reply.started":"2021-07-31T08:47:32.189116Z","shell.execute_reply":"2021-07-31T08:47:32.202712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rolling(roll_me): #input- (7,7,3,96) output-(96,3,7,7)\n    a = swapaxes(roll_me, 3, 0)\n    a = swapaxes(a, 1, 2)\n    a = swapaxes(a, 2, 3)\n    return a","metadata":{"execution":{"iopub.status.busy":"2021-07-31T08:47:32.207593Z","iopub.execute_input":"2021-07-31T08:47:32.20801Z","iopub.status.idle":"2021-07-31T08:47:32.220325Z","shell.execute_reply.started":"2021-07-31T08:47:32.20794Z","shell.execute_reply":"2021-07-31T08:47:32.219015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_load_weight(model):\n    #vggm\n    mat = scipy.io.loadmat('../input/melanoma/datasets/datasets/imagenet/imagenet-vgg-m.mat')\n    #vggm\n    conv2d_58 = [np.array(rolling(mat['layers'][0][0][0][0][2][0][0]),dtype='float32').transpose(), np.array(np.squeeze(mat['layers'][0][0][0][0][2][0][1]),dtype='float32')]\n    conv2d_59 = [np.array(rolling(mat['layers'][0][4][0][0][2][0][0]),dtype='float32').transpose(), np.array(np.squeeze(mat['layers'][0][4][0][0][2][0][1]),dtype='float32')]\n    conv2d_60 = [np.array(rolling(mat['layers'][0][8][0][0][2][0][0]),dtype='float32').transpose(), np.array(np.squeeze(mat['layers'][0][8][0][0][2][0][1]),dtype='float32')]\n    conv2d_61 = [np.array(rolling(mat['layers'][0][10][0][0][2][0][0]),dtype='float32').transpose(), np.array(np.squeeze(mat['layers'][0][10][0][0][2][0][1]),dtype='float32')]\n    conv2d_62 = [np.array(rolling(mat['layers'][0][12][0][0][2][0][0]),dtype='float32').transpose(), np.array(np.squeeze(mat['layers'][0][12][0][0][2][0][1]),dtype='float32')]\n    dense_28 = [np.array(np.reshape(rollaxis(mat['layers'][0][15][0][0][2][0][0], 2),(18432,4096)),dtype='float32'), np.array(np.squeeze(mat['layers'][0][15][0][0][2][0][1]),dtype='float32')]\n    dense_29 = [np.array(np.squeeze(mat['layers'][0][17][0][0][2][0][0]),dtype='float32'), np.array(np.squeeze(mat['layers'][0][17][0][0][2][0][1]),dtype='float32')]\n    dense_30 = [np.array(np.squeeze(mat['layers'][0][19][0][0][2][0][0]),dtype='float32'), np.array(np.squeeze(mat['layers'][0][19][0][0][2][0][1]),dtype='float32')]\n    weights= [conv2d_58,[],[],conv2d_59,[],[],conv2d_60,conv2d_61,conv2d_62,[],[],dense_28,[],dense_29,[],[]] #last layer shape in pre-trained model is (4096,1000), needed (4096,2)\n    i=0\n    for layer in model.layers:\n        if(i == len(weights)-1):\n            break       #not loading the weight of the last layer\n        layer.set_weights(weights[i])\n        i=i+1\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-31T08:47:32.223718Z","iopub.execute_input":"2021-07-31T08:47:32.224267Z","iopub.status.idle":"2021-07-31T08:47:32.247961Z","shell.execute_reply.started":"2021-07-31T08:47:32.224223Z","shell.execute_reply":"2021-07-31T08:47:32.246935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main(train_dir,model_name,protocol,train_retina=False):\n    #protocol1,protocol2,protocol3\n    num_output=2\n    if protocol == \"protocol3\":\n        num_output=3\n    model_save_path=\"./\"+model_name+\"_\"+protocol+\"_weights\"\n    os.mkdir(model_save_path)\n    for i in range(1,6):\n        for j in range(1,3):\n            fold=str(i)+\"x\"+str(j)\n            dest_path=model_save_path+\"/\"+fold\n            os.mkdir(dest_path)\n            print(\"-------------------training:\",fold,\"--------------------------------\")\n            \n            #Load the data\n            print(\"Loading Data\")\n            images,label=load_data(protocol,fold,train_dir,train_retina)\n            datagen = ImageDataGenerator(rotation_range=20,width_shift_range=0.2,height_shift_range=0.2,horizontal_flip=True,validation_split=0.2)\n\n            \n            print(\"VGGM model\")\n            vggm=vgg_m(num_output)\n            \n            #Training only ending dense layers\n            for layer in vggm.layers[:10]:\n                layer.trainable=False\n                    \n            print(\"Loading pre-trained weights\")\n            vggm=model_load_weight(vggm)\n\n            my_callbacks = checkpoints(dest_path)\n            \n            vggm.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.005), metrics=['accuracy',tf.keras.metrics.AUC()])\n            \n            vggm.fit(datagen.flow(images, label, batch_size=12,subset='training'),\n                     validation_data=datagen.flow(images,label, batch_size=8, subset='validation'),\n                     epochs=100,\n                     verbose=1,\n                     callbacks=my_callbacks,)\n            \n            files= sorted(glob(dest_path+\"/*\"))\n            file_name=files[-1]\n            for file in files:\n                if file != file_name:\n                    os.remove(file)\n            ","metadata":{"execution":{"iopub.status.busy":"2021-07-31T08:47:32.250087Z","iopub.execute_input":"2021-07-31T08:47:32.250528Z","iopub.status.idle":"2021-07-31T08:47:32.266003Z","shell.execute_reply.started":"2021-07-31T08:47:32.250471Z","shell.execute_reply":"2021-07-31T08:47:32.264795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name=\"E\"","metadata":{"execution":{"iopub.status.busy":"2021-07-31T08:47:32.267747Z","iopub.execute_input":"2021-07-31T08:47:32.268257Z","iopub.status.idle":"2021-07-31T08:47:32.28416Z","shell.execute_reply.started":"2021-07-31T08:47:32.268213Z","shell.execute_reply":"2021-07-31T08:47:32.283061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main(melanoma_dir,model_name,\"protocol3\")","metadata":{"execution":{"iopub.status.busy":"2021-07-31T08:47:32.286007Z","iopub.execute_input":"2021-07-31T08:47:32.286518Z","iopub.status.idle":"2021-07-31T08:48:06.341494Z","shell.execute_reply.started":"2021-07-31T08:47:32.286474Z","shell.execute_reply":"2021-07-31T08:48:06.33798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import shutil\n#shutil.make_archive('sequence', 'zip', './')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T14:49:42.008495Z","iopub.status.idle":"2021-07-30T14:49:42.009354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"for file in files:\n    data=file.split(\"-\")\n    epoch=data[2]\n    file_name=data[-1]\n    loss= float(file_name.split(\".\")[0]+\".\"+file_name.split(\".\")[1])\n    if loss>min_loss:\n        os.remove(file)\n    else:\n        min_loss=loss \n        file_path=file\n    print(epoch,\" \",file_name,\" \",float(loss),\" \",min_loss)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-30T14:49:42.010858Z","iopub.status.idle":"2021-07-30T14:49:42.011901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import os\n#os.chdir('./')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T14:49:42.013431Z","iopub.status.idle":"2021-07-30T14:49:42.014327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from IPython.display import FileLink\n#FileLink('sequence.zip')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-30T14:49:42.015891Z","iopub.status.idle":"2021-07-30T14:49:42.016852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}